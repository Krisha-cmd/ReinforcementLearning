{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CartPol Environment to balance a stick"
      ],
      "metadata": {
        "id": "HHvzK2bJiTEe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWMgh0tdcYwx"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO #PPO is the algorithm\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv #To vectorize the environments\n",
        "from stable_baselines3.common.evaluation import evaluate_policy #evaluating the model"
      ],
      "metadata": {
        "id": "vtLhXSMGcqRj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Environment"
      ],
      "metadata": {
        "id": "fksQ8zSuhmfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " env_name='CartPole-v1' #prebuilt environment\n",
        " env=gym.make(env_name)"
      ],
      "metadata": {
        "id": "mCFVU3-Wdk4p"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Environment"
      ],
      "metadata": {
        "id": "hBZDtOhGiDmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.reset())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5mm8eujjk06",
        "outputId": "2cd3c66d-e97f-47ce-fe2e-3db59d98474c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.04332942 -0.04489931  0.01443436  0.03380908]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.action_space)\n",
        "print(env.observation_space) #cart position, cart velocity, pole angle, pole angular velocity"
      ],
      "metadata": {
        "id": "YatIGkB1lt4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.action_space.sample() ) #every environment has an action space and an observation space\n",
        "print(env.observation_space.sample())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR1CLaiTkdQ4",
        "outputId": "f4d63f40-63a4-48ff-8f29-2e9f6887ee8a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[ 8.8849670e-01  2.5844497e+38 -3.6456153e-01  2.2438203e+38]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episodes=10 #testing the environment 5 times (for cartpole each episode is 200 frames)\n",
        "for episode in range(episodes):\n",
        "  state=env.reset() #initial state of the environment and set of observations\n",
        "  done=False\n",
        "  score=0\n",
        "\n",
        "  while not done:\n",
        "    env.render() #view the graphical representaion of the environment\n",
        "    action=env.action_space.sample() #random action from the sample action space\n",
        "    n_state,reward,done,info=env.step(action) #getting the new environment variables by passing the action into the environment, next state, reward, is it done?\n",
        "    score+=reward\n",
        "    print('Episode{} Score{}'.format(episode+1,score))"
      ],
      "metadata": {
        "id": "MP0gN7jViBoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        " Model based or Model free?\n",
        "\n",
        "Model-free: only uses the current state values to make a decision\n",
        "A2C, DDPG, DQN, HER, PPO, SAC, TD3\n",
        "\n",
        "Model-based: makes a prediction about the future state of a model to make the best decision for the desired outcome\n",
        "\n",
        " (Model-free algorithm:PPO stable baselines only deals with model-free\n",
        " RL lib can be used for model-based)\n",
        "\n",
        " spinningup.openai.com\n",
        "\n",
        "\n",
        "Algorithm choice depends on:\n",
        "1. Action space"
      ],
      "metadata": {
        "id": "TwlnDJKtme4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#logging and saving logs\n",
        "#log_path=os.path.join('training','logs')\n",
        "model=PPO('MlpPolicy',env,verbose=1,tensorboard_log=\"logs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mhRiBJIMmiWI",
        "outputId": "affde64b-5b10-49da-8515-6f86ea89dee0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training/logs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env=DummyVecEnv([lambda:env]) #part of environment creation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHKa5oorqyu8",
        "outputId": "250d95b2-f93c-4290-a6f8-86a8d871f0fb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=PPO('MlpPolicy',env,verbose=1) #defining the model, multilayer perceptron policy, env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRDmpjLQtqhx",
        "outputId": "d86ea648-ce1c-4094-c27c-a340e8ed6f27"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=20000)"
      ],
      "metadata": {
        "id": "qweXnN6MsJdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"ppo_path\")"
      ],
      "metadata": {
        "id": "umziSOzm05CV"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "veVtiOSp1Fo2"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=PPO.load(\"ppo_path\",env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SicLyrme1Ogr",
        "outputId": "c5457c10-5488-4143-ee38-02c5641e6e83"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "Training Metrics depend on the algorithm\n",
        "\n",
        "- Evaluation metrics\n",
        "    - Episode Length Mean\n",
        "    - Reward Mean\n",
        "\n",
        "- Time Metrics\n",
        "    - fps\n",
        "    - iterations\n",
        "    - time elapsed\n",
        "    - total_timesteps\n",
        "\n",
        "- Loss Metrics\n",
        "    - Entropy_loss\n",
        "    - Policy loss\n",
        "    - Value Loss\n",
        "\n",
        "- Other metrics\n",
        "    - Explained variance\n",
        "    - Learning rate\n",
        "    - n_updates"
      ],
      "metadata": {
        "id": "_jIM86gHpk4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_policy(model,env,n_eval_episodes=10,render=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TboyEJgZ1srg",
        "outputId": "6fe52d04-d7f2-4e15-b195-b04099e4b435"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py:243: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
            "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500.0, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "65zP7Waa5p-9"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing and deploying\n",
        "\n",
        "Time to use the model to take decisions\n",
        "so we predict from the observations and choose the best possible action based on the prediction from the observation\n",
        "\n",
        "obs=env.reset\n",
        "\n",
        "model.predict(obs)\n"
      ],
      "metadata": {
        "id": "jQsYbOKd5t08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#action, _=model.predict(obs)\n",
        "env=gym.make('CartPole-v1')\n",
        "env=DummyVecEnv([lambda:env])\n",
        "obs=env.reset() #initial observations\n",
        "model.predict(obs) #gives a prediction of action (not next state)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQGt8F376q2F",
        "outputId": "26796d34-6981-4910-82d4-16f47f6ade2b"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.03619986  0.02306512  0.0447387  -0.01729192]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0]), None)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ir0Nv0U_9w9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes=10\n",
        "for episode in range(episodes):\n",
        "  obs=env.reset()\n",
        "  done=False\n",
        "  score=0\n",
        "\n",
        "  while not done:\n",
        "    env.render()\n",
        "    action,_=model.predict(obs)\n",
        "    obs,reward,done,info=env.step(action)\n",
        "    score+=reward\n",
        "    print('Episode{} Score{}'.format(episode+1,score))"
      ],
      "metadata": {
        "id": "Svls0nSU53UN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}